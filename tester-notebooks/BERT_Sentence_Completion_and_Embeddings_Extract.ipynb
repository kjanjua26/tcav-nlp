{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model - Post Training Setup\n",
    "\n",
    "Use BERT and run it for the sentence completion problem, state-of-the-art model. Then remove the last layer and modify it to return embeddings for the input instead of a single output: the word to complete the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True,)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"The river bank was flooded.\",\n",
    "         \"The bank vault was robust.\",\n",
    "         \"He had to bank on her for support.\",\n",
    "         \"The bank was out of money.\",\n",
    "         \"The bank teller was a man.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "    return list_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "\n",
    "for text in texts:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    word_index = tokenized_text.index('bank')\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  3\n",
      "[-0.13987627625465393, -0.4429723620414734, 0.12858182191848755, -0.03672254830598831, 0.14131620526313782]\n",
      "768\n",
      "====================================================================================================\n",
      "Index:  2\n",
      "[0.6443396806716919, -0.7919419407844543, 0.02263902686536312, 0.0009034294635057449, 0.6554418206214905]\n",
      "768\n",
      "====================================================================================================\n",
      "Index:  4\n",
      "[-0.057423096150159836, -0.6665879487991333, -0.3368636965751648, -0.42104634642601013, 0.9046264886856079]\n",
      "768\n",
      "====================================================================================================\n",
      "Index:  2\n",
      "[0.7917051911354065, -0.5113241076469421, -0.030860211700201035, -0.06428904831409454, 1.1648433208465576]\n",
      "768\n",
      "====================================================================================================\n",
      "Index:  2\n",
      "[0.7716076374053955, -0.403091162443161, -0.29921817779541016, 0.05266457796096802, 0.361716628074646]\n",
      "768\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    word_index = tokenized_text.index('bank')\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "    print('Index: ', word_index)\n",
    "    print(word_embedding[:5])\n",
    "    print(len(word_embedding))\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_and_embeddings_dict = {'words': [], 'embeds': []}\n",
    "for text in texts:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    for tok in tokenized_text:\n",
    "        word_index = tokenized_text.index(tok)\n",
    "        word_embedding = list_token_embeddings[word_index]\n",
    "        word_and_embeddings_dict['words'].append(tok)\n",
    "        word_and_embeddings_dict['embeds'].append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [-0.37874600291252136, -0.0703376978635788, -0.36608144640922546, -0.10915069282054901, -0.24549156427383423]\n",
      "the [-0.06094054505228996, -0.39486756920814514, -0.5337704420089722, 0.17299635708332062, 0.2710832357406616]\n",
      "river [0.2703665792942047, 0.2709972560405731, -0.3092411458492279, 0.1405070573091507, 0.43297654390335083]\n",
      "bank [-0.13987627625465393, -0.4429723620414734, 0.12858182191848755, -0.03672254830598831, 0.14131620526313782]\n",
      "was [-0.3832331895828247, -0.6323017477989197, -0.4131511449813843, 0.024052325636148453, 0.2380470335483551]\n",
      "flooded [0.32402217388153076, -0.5755363702774048, 0.16925807297229767, -0.15234218537807465, 0.8776127099990845]\n",
      ". [0.5574973225593567, 0.1583925187587738, -0.570341944694519, 0.4329517185688019, -0.20079463720321655]\n",
      "[SEP] [0.3168503940105438, 0.41758719086647034, -0.5019322633743286, 0.38555893301963806, 0.3209969103336334]\n",
      "[CLS] [-0.3363654613494873, -0.3163451850414276, -0.0863780677318573, 0.0032097669318318367, -0.1854727864265442]\n",
      "the [-0.40259385108947754, -0.3413439095020294, -0.5882834792137146, 0.24971505999565125, 0.3136751055717468]\n",
      "bank [0.6443396806716919, -0.7919419407844543, 0.02263902686536312, 0.0009034294635057449, 0.6554418206214905]\n",
      "vault [0.6018880605697632, -0.5887721180915833, 0.10185131430625916, 0.046309251338243484, 1.223393440246582]\n",
      "was [-0.38945072889328003, -0.4491642713546753, -0.23625048995018005, -0.026269929483532906, 0.104995958507061]\n",
      "robust [-0.10725261270999908, 0.11119931191205978, 0.07953276485204697, 0.11941065639257431, 0.051533542573451996]\n",
      ". [0.5719445943832397, -0.00474932324141264, -0.3307029604911804, 0.263144850730896, -0.0058972276747226715]\n",
      "[SEP] [0.7218727469444275, 0.01503906399011612, -0.13109247386455536, 0.4442302882671356, -0.06949782371520996]\n",
      "[CLS] [-0.13808293640613556, -0.0831930860877037, -0.3376995325088501, 0.07677263766527176, -0.5361587405204773]\n",
      "he [0.3772727847099304, 0.2470395863056183, -0.0383407361805439, 0.6789921522140503, 0.2714740037918091]\n",
      "had [1.043357491493225, -0.01217365637421608, -0.8337380886077881, -0.15491895377635956, -0.20666301250457764]\n",
      "to [0.20239858329296112, -0.1853959560394287, -0.9755947589874268, -0.3073658347129822, -0.07229922711849213]\n",
      "bank [-0.057423096150159836, -0.6665879487991333, -0.3368636965751648, -0.42104634642601013, 0.9046264886856079]\n",
      "on [-0.03029552847146988, 0.14149460196495056, 0.2527516484260559, -0.40895596146583557, -0.07460219413042068]\n",
      "her [0.21996141970157623, -0.6749308705329895, -0.1001102477312088, -0.41325271129608154, 0.2060646116733551]\n",
      "for [0.2245115041732788, -0.6231189370155334, 0.9234911799430847, -0.14167656004428864, -0.508097231388092]\n",
      "support [-0.07595464587211609, -0.03580673784017563, 0.0829799622297287, -0.7020984888076782, 0.4987941384315491]\n",
      ". [0.5291031002998352, -0.07490894198417664, -0.3220040798187256, 0.389615923166275, -0.2878306210041046]\n",
      "[SEP] [0.4240732491016388, -0.11721605062484741, -0.02940291538834572, 0.22238561511039734, -0.19159206748008728]\n",
      "[CLS] [-0.03189913555979729, 0.41662856936454773, -0.418639212846756, -0.08559754490852356, -0.5972751975059509]\n",
      "the [0.38373300433158875, 0.16180932521820068, -0.6934249997138977, 0.13372284173965454, -0.36496779322624207]\n",
      "bank [0.7917051911354065, -0.5113241076469421, -0.030860211700201035, -0.06428904831409454, 1.1648433208465576]\n",
      "was [0.3183276951313019, -0.14228424429893494, -0.33904391527175903, -0.09304682910442352, -0.3613647520542145]\n",
      "out [-0.21556617319583893, -0.20037448406219482, -0.09949234127998352, -0.05760205537080765, 0.1311490535736084]\n",
      "of [-0.22937385737895966, -0.4188510477542877, -0.12325438857078552, -0.14382489025592804, 0.5166400671005249]\n",
      "money [0.048571933060884476, -0.7598138451576233, -0.41040557622909546, 0.06931829452514648, 1.0897749662399292]\n",
      ". [0.5552477240562439, 0.0766526386141777, -0.4177330732345581, 0.35922011733055115, -0.06136336177587509]\n",
      "[SEP] [0.751961350440979, 0.1611691415309906, -0.15698829293251038, 0.5775439143180847, -0.12565875053405762]\n",
      "[CLS] [-0.19441884756088257, -0.0735398381948471, -0.47574958205223083, 0.06099255383014679, -0.15676221251487732]\n",
      "the [-0.31027981638908386, -0.30565571784973145, -0.7455472350120544, 0.2970427870750427, -0.025580180808901787]\n",
      "bank [0.7716076374053955, -0.403091162443161, -0.29921817779541016, 0.05266457796096802, 0.361716628074646]\n",
      "teller [0.16109591722488403, -0.6295639276504517, -0.488992840051651, -0.20365019142627716, 0.6739639639854431]\n",
      "was [0.16483040153980255, -0.36720171570777893, -0.7518153190612793, -0.5309343338012695, -0.08973513543605804]\n",
      "a [0.2775868773460388, 0.10814889520406723, -0.7111880779266357, -0.07735327631235123, 0.32600510120391846]\n",
      "man [0.14416861534118652, 0.3215058743953705, -0.17294850945472717, -0.17687682807445526, 0.010700155049562454]\n",
      ". [0.5098921060562134, 0.15197446942329407, -0.4704200327396393, 0.3556714653968811, -0.03385021165013313]\n",
      "[SEP] [0.6157125234603882, 0.22501912713050842, -0.3400573134422302, 0.6092475652694702, -0.05231311917304993]\n"
     ]
    }
   ],
   "source": [
    "for word, embed in zip(word_and_embeddings_dict['words'], word_and_embeddings_dict['embeds']):\n",
    "    print(word, embed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
